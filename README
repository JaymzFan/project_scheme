Utworzę uniwersalny skrypt do analizy danych w forme data.frame do celów modelowania deskryptywnego oraz predykcyjnego.

W tym momencie myślę aby stworzyć skrypt, w którym data.frame przejdzie kilka kluczowych kroków:

1. oczyszczenie zmiennych :
                          wczytanie zbioru oraz automatyczne wykrycie kodowania
                          utworzenie etykiet wartości
                          etykiet zmiennych + Kilka zmiennych, które nie będą oczyszczone dla debuggowania
                          utworzenie podgrup zmiennych w wektorach nazw kolumn, indep, dep, indep$numerical, indep$categorical itp.

1b. manipulacja danymi : szczególne przypadki dplyr (gdy zmienne są przekazywane stringami itp), 
                         szczególne przypadki tidyr:: spread i gather dokładnie wyjaśnione i wytłumaczone
                         Generalnie weź cheatsheet do tych dwóch i sprawdź co się może przydać. 
                         Zeksplorować temat by() i pokrewnych. Jak wyciągnąć to w łatwy sposób w tabele ??? 
                         Ogarnąć dummies() i tworzenie dummy variables. Najlepiej wykorzystaj dummies::dummy.data.frame()
                         zekspolorować := oraz !!!
                         różne typy group_by, razem summarize_at itp. 
                         
2. krótka historia danych: skąd pochodzą dane, jakie są moje wątpliwości, czego nie wiem, co wiem na pewno. Wszystko co może się
                           przydać do diagnozy ewentualnych problemów. Na pewno musza się znaleźć bloki: 
                           źródła danych + opis datasetów co się w nich znajduje (ścieżki do plików + opisy). To głównie do Markdown'a
                           
2. Analiza braków danych: sprawdzenie typów braków danych, poszukania schematów 
                          zwizualizowanie braków danych w tabelach i w wykresach, 
                          przegląd metod imputacji z parametrami i KPI'sami, 
                          przegląd typów imputacji w zależności od typu braku,
                          ewentualna opcja rekodowania braków danych
                          
3. Eksploracja wizualizacja i związki: 
                          TESTY i typy korelacji wraz z uzasadnieniem i założeniami,
                          TESTY i typy niezależności zmiennych róznego rodzaju,
                           wyszukanie i zwizualizowanie korelacji liniowych w tabelach i wykresach,
                           zwizualizowanie związków między zmiennymi zależnymi a zmiennymi niezależnymi, 
                             zwizualizowanie korelacji powinnno na wyjściu dać możliwość utworzenia 
                             data.frame nazw kolumn z podanymi poziomami korelacji, istotnością oraz kategoria (wysoka,średnia,niska)
                             korelacja w zależności od podanych cutpointów lub kwartyli.
 
                           Identyfikacja związków nieliniowych wraz z wykresami w ggplocie do każdej kombinacji typów zmiennych
                           W jaki sposób znajdować związki nieliniowe? Może loessy z jakimiś poziomami ufności? 
                           
                           https://www3.nd.edu/~rwilliam/stats2/l61.pdf
                           
3a.Eksploracja wizualizacja i związki wielowymiarowe: 

                           Identyfikacja związków nieliniowych oraz zwiazków pomiędzy większą ilością zmiennych, conajmniej 3 zmiennych 
                           Co robić w przypadku ewidentnych związków nieliniowych? 
                           estymacja rozkładu zmiennej -> określenie z jakiego rozkładu pochodzi zmienna i może wypada sprowadzić do innego normalnego?
                            może zależy to od metody modelowania
                           PCA, PLS
                           
3c. Transformacje i skalowanie zmiennych:
                           Generalnie Feature engineering: znaleźć optymalne sposoby kategoryzacji zmiennych ciągłych wraz z jakimiś statystykami,
                           Ipsatyzacja, mean-centrowanie, skalowanie zmiennych, normalizacja, standaryzacja 
                           ( WRAZ Z UZASADNIENIEM KIEDY MOŻNA UŻYWAĆ KTÓREGO)
                           
4. Eksploracja Wyciągnięcie ukrytych związków: Analiza głównych składowych, analiza czynnikowa, analiza korespondencji, 
                                      segmentacja (k-means, hclust, svm), odpowiedni wybór liczenia odległości !!! wraz z algorytmem odtwarzającym i pełnymi wynikami opisowymi, 
                                      Ograniczenie wymiarów, przy segmentacji stymulanty/destymulanty??? czemu trzebea 
                                      Dlaczeg oprzed policzeniem tablicy odległości wyrzuciłem zmienne mocno skorelowane? SGGW
                                      Ranking obiektów, smr SGGW
                                      
4a. Walidacja danych: Opis sensowności danych, pełen opis i charakterystyka danych, przegląd wartości, wartości brakujących,
                      związków ujawnionych w danych, pełna historia tego co widać na podstawie rozkłądów zmiennych 
4b. Poprawa rozkładów zmiennych : w przypadku skrajnych wahań struktury zastanowić się co jest priorytetem : trafność na ogóle, trafność
                                wewnątrz klas, trafność konkretnej klasy? Co można zrobić zeby wyrównać strukturę
5. Dobór zmiennych do modelu : na podstawie korelacji, nośnika informacji, aic, wariancja, p-value, testy niezależności itp.,
                                Przegląd metod statystycznych do doboru zmiennych PLUS krótki opis czego się spodziewać po każdej
                                z metod i na czym bazują te metody
6. Wybór typu modelu klasyfikacyjne : regresja logistyczna/uporzadkowana/multinom (pamiętać o wykresach od logitu), lasy losowe, xgboost. 
                                    Do każdego typu modelu pełen opis założeń plus diagnostyka
                                    Metody unsupervised 
7. Wybór typu modelu regresyjne : regresja liniowa, lasy losowe, modele nieliniowe, xgboost?, modele hierarchiczne + identyfikacja !!! 
                                  modele mieszane
                                  Do każdego typu modelu pełen opis założeń plus diagnostyka. TRANFORMACJE ZMIENNYCH I WIELORÓWNANIÓWKA
                                  Multivariate Fay–Herriot models for estimating small area indicators
7aa. Szeregi czasowe :   dekompozycja, prognozowanie, modele wielorównaniowe, stacjonarność, testy autokorelacji, sARIMA                                  
7a. Diagnostyka modelu : w przypadku klasyfikacyjnych doskonale opisane confussionMatrix, acc, precision, uplifty itd., wykresy ROC, 
                         poziomy odcięcia, poziomy błędów itp. 
                         w przypadku regresyjnych, RMSE , MSE, wszystkie typy błędów, Rkwadrat ( WSZYSTKIE TYPY Rkwadrat z uzasadnieniem
                         którego powinienem się słuchać), analiza reszt i założeń wstępnych modelu, benchmarki dla r kwadrat wg typu zadania
8a. Modele i analiza danych przestrzennych : Generalnie wszystko o pracy z mapami i shape-file'm
8. Ewaluacja oraz raportowanie : Pełen opis w MarkDown tego co zostało wykonane w modelu, szablon do każdego elementu działania 
                                na zbiorze danych, pełen zestaw wykresów i wniosków z każdego momentu analizy. 

9. Deep learning
10. KERAS, e1071, shiny, leaflet

                        https://www.r-bloggers.com/supervised-vs-unsupervised-learning-exploring-brexit-with-pls-and-pca/
                        http://www.statystyka.az.pl/miary-rozkladu/miary-zmiennosci.php
                        http://www.sthda.com/english/wiki/normality-test-in-r
                        http://library.sadjad.ac.ir/opac//temp/19241.pdf
                        https://bookdown.org/nowosad/Geostatystyka/wprowadzenie.html
                        http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html
https://sebastianraschka.com/Articles/2014_python_lda.html
http://www.rpubs.com/Kushan/295412
`https://www3.nd.edu/~rwilliam/stats2/l61.pdf
https://www.statsoft.pl/textbook/stathome_stat.html?https%3A%2F%2Fwww.statsoft.pl%2Ftextbook%2Fstgrm.html
https://www.analyticsvidhya.com/blog/2015/08/list-r-packages-data-analysis/
https://cmdlinetips.com/2018/01/data-visualization-with-r-a-new-online-book/
https://www.datacareer.ch/blog/top-10-r-packages-for-data-science/
https://www.computerworld.com/article/2921176/business-intelligence/great-r-packages-for-data-import-wrangling-visualization.html
https://towardsdatascience.com/top-r-libraries-for-data-science-9b24f658e243
https://medium.com/activewizards-machine-learning-company/top-20-r-libraries-for-data-science-in-2018-infographic-956f8419f883
https://heartbeat.fritz.ai/top-7-libraries-and-packages-of-the-year-for-data-science-and-ai-python-r-6b7cca2bf000
