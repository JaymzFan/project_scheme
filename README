Utworzę uniwersalny skrypt do analizy danych w forme data.frame do celów modelowania deskryptywnego oraz predykcyjnego.

W tym momencie myślę aby stworzyć skrypt, w którym data.frame przejdzie kilka kluczowych kroków:

1. oczyszczenie zmiennych :
                          wczytanie zbioru oraz automatyczne wykrycie kodowania
                          utworzenie etykiet wartości
                          etykiet zmiennych + Kilka zmiennych, które nie będą oczyszczone dla debuggowania
                          utworzenie podgrup zmiennych w wektorach nazw kolumn, indep, dep, indep$numerical, indep$categorical itp.
                          
2. krótka historia danych: skąd pochodzą dane, jakie są moje wątpliwości, czego nie wiem, co wiem na pewno. Wszystko co może się
                           przydać do diagnozy ewentualnych problemów. Na pewno musza się znaleźć bloki: 
                           źródła danych + opis datasetów co się w nich znajduje (ścieżki do plików + opisy). To głównie do Markdown'a
                           
2. Analiza braków danych: sprawdzenie typów braków danych, poszukania schematów 
                          zwizualizowanie braków danych w tabelach i w wykresach, 
                          przegląd metod imputacji z parametrami i KPI'sami, 
                          przegląd typów imputacji w zależności od typu braku,
                          ewentualna opcja rekodowania braków danych
                          
3. Eksploracja wizualizacja i związki: 
                          TESTY i typy korelacji wraz z uzasadnieniem i założeniami,
                          TESTY i typy niezależności zmiennych róznego rodzaju,
                           wyszukanie i zwizualizowanie korelacji liniowych w tabelach i wykresach,
                           zwizualizowanie związków między zmiennymi zależnymi a zmiennymi niezależnymi, 
                             zwizualizowanie korelacji powinnno na wyjściu dać możliwość utworzenia 
                             data.frame nazw kolumn z podanymi poziomami korelacji, istotnością oraz kategoria (wysoka,średnia,niska)
                             korelacja w zależności od podanych cutpointów lub kwartyli.
 
                           Identyfikacja związków nieliniowych wraz z wykresami w ggplocie do każdej kombinacji typów zmiennych
                           W jaki sposób znajdować związki nieliniowe? Może loessy z jakimiś poziomami ufności? 
                           
3a.Eksploracja wizualizacja i związki wielowymiarowe: 

                           Identyfikacja związków nieliniowych oraz zwiazków pomiędzy większą ilością zmiennych, conajmniej 3 zmiennych 
                           Co robić w przypadku ewidentnych związków nieliniowych? 
                           estymacja rozkładu zmiennej -> określenie z jakiego rozkładu pochodzi zmienna i może wypada sprowadzić do innego normalnego?
                            może zależy to od metody modelowania
                           PCA, PLS
                           
3c. Transformacje i skalowanie zmiennych:
                           Ipsatyzacja, mean-centrowanie, skalowanie zmiennych, normalizacja, standaryzacja 
                           ( WRAZ Z UZASADNIENIEM KIEDY MOŻNA UŻYWAĆ KTÓREGO)
                           
4. Eksploracja Wyciągnięcie ukrytych związków: Analiza głównych składowych, analiza czynnikowa, analiza korespondencji, 
                                      segmentacja (k-means, hclust, svm) !!! wraz z algorytmem odtwarzającym i pełnymi wynikami opisowymi, 
                                      Ograniczenie wymiarów
                                      
4a. Walidacja danych: Opis sensowności danych, pełen opis i charakterystyka danych, przegląd wartości, wartości brakujących,
                      związków ujawnionych w danych, pełna historia tego co widać na podstawie rozkłądów zmiennych 
4b. Poprawa rozkładów zmiennych : w przypadku skrajnych wahań struktury zastanowić się co jest priorytetem : trafność na ogóle, trafność
                                wewnątrz klas, trafność konkretnej klasy? Co można zrobić zeby wyrównać strukturę
5. Dobór zmiennych do modelu : na podstawie korelacji, nośnika informacji, aic, wariancja, p-value, testy niezależności itp.,
                                Przegląd metod statystycznych do doboru zmiennych PLUS krótki opis czego się spodziewać po każdej
                                z metod i na czym bazują te metody
6. Wybór typu modelu klasyfikacyjne : regresja logistyczna/uporzadkowana/multinom (pamiętać o wykresach od logitu), lasy losowe, xgboost. 
                                    Do każdego typu modelu pełen opis założeń plus diagnostyka
                                    Metody unsupervised 
7. Wybór typu modelu regresyjne : regresja liniowa, lasy losowe, modele nieliniowe, xgboost?, modele hierarchiczne + identyfikacja !!! 
                                  Do każdego typu modelu pełen opis założeń plus diagnostyka. TRANFORMACJE ZMIENNYCH I WIELORÓWNANIÓWKA
                                  Multivariate Fay–Herriot models for estimating small area indicators
7a. Diagnostyka modelu : w przypadku klasyfikacyjnych doskonale opisane confussionMatrix, acc, precision, uplifty itd., wykresy ROC, 
                         poziomy odcięcia, poziomy błędów itp. 
                         w przypadku regresyjnych, RMSE , MSE, wszystkie typy błędów, Rkwadrat ( WSZYSTKIE TYPY Rkwadrat z uzasadnieniem
                         którego powinienem się słuchać), analiza reszt i założeń wstępnych modelu, benchmarki dla r kwadrat wg typu zadania
8. Ewaluacja oraz raportowanie : Pełen opis w MarkDown tego co zostało wykonane w modelu, szablon do każdego elementu działania 
                                na zbiorze danych, pełen zestaw wykresów i wniosków z każdego momentu analizy. 


                        
